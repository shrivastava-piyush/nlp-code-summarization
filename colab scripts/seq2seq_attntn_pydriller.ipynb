{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_attntn_pydriller",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jfD28cA1hZQ"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "import re           \r\n",
        "import os\r\n",
        "from keras.preprocessing.text import Tokenizer \r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from nltk.corpus import stopwords   \r\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.python.keras.layers import Layer\r\n",
        "from tensorflow.python.keras import backend as K\r\n",
        "\r\n",
        "import warnings\r\n",
        "pd.set_option(\"display.max_colwidth\", 200)\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "from keras import backend as K \r\n",
        "\r\n",
        "import copy\r\n",
        "import re\r\n",
        "import tarfile"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cMx9PuK51j6q",
        "outputId": "ca496351-9a47-4ddf-c501-d683df97dac3"
      },
      "source": [
        "def get_c_data(remove_id=True, sample_size=20000, start_token='\\t', end_token='\\n'):\r\n",
        "\r\n",
        "  # Convert downloaded json files into a dataframe\r\n",
        "  c_data = pd.read_csv('pydriller_14k_filtered.csv')\r\n",
        "  c_data = c_data[c_data['Message'].str.len() < 600]\r\n",
        "  return c_data['Code'].tolist()[:sample_size], c_data['Message'].tolist()[:sample_size]\r\n",
        "\r\n",
        "input_data, target_data = get_c_data(start_token='', end_token='')\r\n",
        "\r\n",
        "df = pd.DataFrame({'Function': [], 'Comments': []})\r\n",
        "df['Function'] = input_data\r\n",
        "df['Comments'] = target_data\r\n",
        "\r\n",
        "df['Comments'] = '_START_ ' + df['Comments'] + ' _END_'\r\n",
        "\r\n",
        "max_len_text = max([len(txt.split()) for txt in input_data])\r\n",
        "max_len_summary = max([len(txt.split()) for txt in target_data])\r\n",
        "print(max_len_summary)\r\n",
        "\r\n",
        "train_data,x_val,train_labels,y_val=train_test_split(df['Function'], df['Comments'],test_size=0.1,random_state=0,shuffle=True)\r\n",
        "\r\n",
        "#prepare a tokenizer for reviews on training data\r\n",
        "x_tokenizer = Tokenizer()\r\n",
        "x_tokenizer.fit_on_texts(list(train_data))\r\n",
        "\r\n",
        "#convert text sequences into integer sequences\r\n",
        "train_data    =   x_tokenizer.texts_to_sequences(train_data) \r\n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\r\n",
        "\r\n",
        "#padding zero upto maximum length\r\n",
        "train_data    =   pad_sequences(train_data,  maxlen=max_len_text, padding='post') \r\n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\r\n",
        "\r\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1\r\n",
        "\r\n",
        "#preparing a tokenizer for summary on training data \r\n",
        "y_tokenizer = Tokenizer()\r\n",
        "y_tokenizer.fit_on_texts(list(train_labels))\r\n",
        "\r\n",
        "#convert summary sequences into integer sequences\r\n",
        "train_labels    =   y_tokenizer.texts_to_sequences(train_labels) \r\n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \r\n",
        "\r\n",
        "#padding zero upto maximum length\r\n",
        "train_labels    =   pad_sequences(train_labels, maxlen=max_len_summary, padding='post')\r\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\r\n",
        "\r\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1\r\n",
        "\r\n",
        "class AttentionLayer(Layer):\r\n",
        "    \"\"\"\r\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\r\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\r\n",
        "     \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        assert isinstance(input_shape, list)\r\n",
        "        # Create a trainable weight variable for this layer.\r\n",
        "\r\n",
        "        self.W_a = self.add_weight(name='W_a',\r\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\r\n",
        "                                   initializer='uniform',\r\n",
        "                                   trainable=True)\r\n",
        "        self.U_a = self.add_weight(name='U_a',\r\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\r\n",
        "                                   initializer='uniform',\r\n",
        "                                   trainable=True)\r\n",
        "        self.V_a = self.add_weight(name='V_a',\r\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\r\n",
        "                                   initializer='uniform',\r\n",
        "                                   trainable=True)\r\n",
        "\r\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\r\n",
        "\r\n",
        "    def call(self, inputs, verbose=False):\r\n",
        "        \"\"\"\r\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\r\n",
        "        \"\"\"\r\n",
        "        assert type(inputs) == list\r\n",
        "        encoder_out_seq, decoder_out_seq = inputs\r\n",
        "        if verbose:\r\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\r\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\r\n",
        "\r\n",
        "        def energy_step(inputs, states):\r\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\r\n",
        "\r\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\r\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\r\n",
        "\r\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\r\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\r\n",
        "            de_hidden = inputs.shape[-1]\r\n",
        "\r\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\r\n",
        "            # <= batch_size*en_seq_len, latent_dim\r\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\r\n",
        "            # <= batch_size*en_seq_len, latent_dim\r\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\r\n",
        "            if verbose:\r\n",
        "                print('wa.s>',W_a_dot_s.shape)\r\n",
        "\r\n",
        "            \"\"\" Computing hj.Ua \"\"\"\r\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\r\n",
        "            if verbose:\r\n",
        "                print('Ua.h>',U_a_dot_h.shape)\r\n",
        "\r\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\r\n",
        "            # <= batch_size*en_seq_len, latent_dim\r\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\r\n",
        "            if verbose:\r\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\r\n",
        "\r\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\r\n",
        "            # <= batch_size, en_seq_len\r\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\r\n",
        "            # <= batch_size, en_seq_len\r\n",
        "            e_i = K.softmax(e_i)\r\n",
        "\r\n",
        "            if verbose:\r\n",
        "                print('ei>', e_i.shape)\r\n",
        "\r\n",
        "            return e_i, [e_i]\r\n",
        "\r\n",
        "        def context_step(inputs, states):\r\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\r\n",
        "            # <= batch_size, hidden_size\r\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\r\n",
        "            if verbose:\r\n",
        "                print('ci>', c_i.shape)\r\n",
        "            return c_i, [c_i]\r\n",
        "\r\n",
        "        def create_inital_state(inputs, hidden_size):\r\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\r\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\r\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\r\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\r\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\r\n",
        "            return fake_state\r\n",
        "\r\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\r\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\r\n",
        "\r\n",
        "        \"\"\" Computing energy outputs \"\"\"\r\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\r\n",
        "        last_out, e_outputs, _ = K.rnn(\r\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\r\n",
        "        )\r\n",
        "\r\n",
        "        \"\"\" Computing context vectors \"\"\"\r\n",
        "        last_out, c_outputs, _ = K.rnn(\r\n",
        "            context_step, e_outputs, [fake_state_c],\r\n",
        "        )\r\n",
        "\r\n",
        "        return c_outputs, e_outputs\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\r\n",
        "        return [\r\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\r\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\r\n",
        "        ]\r\n",
        "\r\n",
        "K.clear_session() \r\n",
        "latent_dim = 256\r\n",
        "\r\n",
        "# Encoder \r\n",
        "encoder_inputs = Input(shape=(max_len_text,)) \r\n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \r\n",
        "\r\n",
        "#LSTM 1 \r\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \r\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \r\n",
        "\r\n",
        "#LSTM 2 \r\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \r\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \r\n",
        "\r\n",
        "#LSTM 3 \r\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \r\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \r\n",
        "\r\n",
        "# Set up the decoder. \r\n",
        "decoder_inputs = Input(shape=(None,)) \r\n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \r\n",
        "dec_emb = dec_emb_layer(decoder_inputs) \r\n",
        "\r\n",
        "#LSTM using encoder_states as initial state\r\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \r\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \r\n",
        "\r\n",
        "#Attention Layer\r\n",
        "attn_layer = AttentionLayer(name='attention_layer') \r\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \r\n",
        "\r\n",
        "# Concat attention output and decoder LSTM output \r\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\r\n",
        "\r\n",
        "#Dense layer\r\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \r\n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \r\n",
        "\r\n",
        "# Define the model\r\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\r\n",
        "\r\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\r\n",
        "history=model.fit([train_data,train_labels[:,:-1]], train_labels.reshape(train_labels.shape[0],train_labels.shape[1], 1)[:,1:], epochs=50, steps_per_epoch=100, callbacks=[es],batch_size=64, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\r\n",
        "\r\n",
        "reverse_target_word_index=y_tokenizer.index_word \r\n",
        "reverse_source_word_index=x_tokenizer.index_word \r\n",
        "target_word_index=y_tokenizer.word_index\r\n",
        "\r\n",
        "# encoder inference\r\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\r\n",
        "\r\n",
        "# decoder inference\r\n",
        "# Below tensors will hold the states of the previous time step\r\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\r\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\r\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\r\n",
        "\r\n",
        "# Get the embeddings of the decoder sequence\r\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\r\n",
        "\r\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\r\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\r\n",
        "\r\n",
        "#attention inference\r\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\r\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\r\n",
        "\r\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\r\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\r\n",
        "\r\n",
        "# Final decoder model\r\n",
        "decoder_model = Model(\r\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\r\n",
        "[decoder_outputs2] + [state_h2, state_c2])\r\n",
        "\r\n",
        "def decode_sequence(input_seq):\r\n",
        "    # Encode the input as state vectors.\r\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\r\n",
        "    #print('input_seq: {}, e_out: {} '.format(input_seq,e_out))\r\n",
        "    # Generate empty target sequence of length 1.\r\n",
        "    target_seq = np.zeros((1,1))\r\n",
        "\r\n",
        "    # Chose the 'start' word as the first word of the target sequence\r\n",
        "    target_seq[0, 0] = target_word_index['start']\r\n",
        "\r\n",
        "    stop_condition = False\r\n",
        "    decoded_sentence = ''\r\n",
        "    while not stop_condition:\r\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\r\n",
        "\r\n",
        "        # Sample a token\r\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\r\n",
        "        if sampled_token_index == 0:\r\n",
        "          print(\"keyerror\")\r\n",
        "          continue\r\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\r\n",
        "        #print(\"sampled_token:\",sampled_token)\r\n",
        "        if(sampled_token!='end'):\r\n",
        "            decoded_sentence += ' '+sampled_token\r\n",
        "\r\n",
        "            # Exit condition: either hit max length or find stop word.\r\n",
        "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\r\n",
        "                stop_condition = True\r\n",
        "\r\n",
        "        # Update the target sequence (of length 1).\r\n",
        "        target_seq = np.zeros((1,1))\r\n",
        "        target_seq[0, 0] = sampled_token_index\r\n",
        "        # stop_condition = True\r\n",
        "        # Update internal states\r\n",
        "        e_h, e_c = h, c\r\n",
        "\r\n",
        "    return decoded_sentence\r\n",
        "\r\n",
        "def sequence_to_comment(input_seq):\r\n",
        "    newString=''\r\n",
        "    for i in input_seq:\r\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\r\n",
        "        newString=newString+reverse_target_word_index[i]+' '\r\n",
        "    return newString\r\n",
        "\r\n",
        "def sequence_to_code(input_seq):\r\n",
        "    newString=''\r\n",
        "    for i in input_seq:\r\n",
        "      if(i!=0):\r\n",
        "        newString=newString+reverse_source_word_index[i]+' '\r\n",
        "    return newString\r\n",
        "\r\n",
        "\r\n",
        "results = pd.DataFrame({'Function':[], 'Original Comment':[], 'Predicted comment':[]})\r\n",
        "\r\n",
        "function, o_comment, p_comment = [], [], []\r\n",
        "for i in range(len(x_val[:1000])):\r\n",
        "  function.append(sequence_to_code(x_val[i]))\r\n",
        "  o_comment.append(sequence_to_comment(y_val[i]))\r\n",
        "  p_comment.append(decode_sequence(x_val[i].reshape(1,max_len_text)))\r\n",
        "\r\n",
        "results['Function'] = function\r\n",
        "results['Original Comment'] = o_comment\r\n",
        "results['Predicted comment'] = p_comment\r\n",
        "\r\n",
        "results.to_csv(\"results_seq2seq_attention_codesearch.csv\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 162)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 162, 256)     4868352     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 162, 256), ( 525312      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 162, 256), ( 525312      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    4771328     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 162, 256), ( 525312      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 18638)  9561294     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 21,433,550\n",
            "Trainable params: 21,433,550\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "100/100 [==============================] - 40s 398ms/step - loss: 2.1179 - val_loss: 1.6088\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.6315 - val_loss: 1.4316\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 38s 383ms/step - loss: 1.4810 - val_loss: 1.3765\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.4235 - val_loss: 1.3340\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.3624 - val_loss: 1.2972\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.3259 - val_loss: 1.2756\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.2751 - val_loss: 1.2510\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.2866 - val_loss: 1.2316\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 38s 385ms/step - loss: 1.2329 - val_loss: 1.2117\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.2095 - val_loss: 1.1987\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.1886 - val_loss: 1.1862\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 38s 381ms/step - loss: 1.1644 - val_loss: 1.1726\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.1645 - val_loss: 1.1641\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.1363 - val_loss: 1.1569\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.1160 - val_loss: 1.1491\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 38s 380ms/step - loss: 1.0987 - val_loss: 1.1465\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 38s 383ms/step - loss: 1.1047 - val_loss: 1.1375\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 38s 381ms/step - loss: 1.0684 - val_loss: 1.1363\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 38s 382ms/step - loss: 1.0599 - val_loss: 1.1314\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 38s 381ms/step - loss: 1.0415 - val_loss: 1.1336\n",
            "Epoch 00020: early stopping\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n",
            "keyerror\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6a82c3d3edc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    303\u001b[0m   \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0mo_comment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_to_comment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0mp_comment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Function'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6a82c3d3edc2>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# Sample a token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1593\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[1;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    720\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m    721\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         gen_experimental_dataset_ops.make_data_service_iterator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3005\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   3006\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MakeIterator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m         tld.op_callbacks, dataset, iterator)\n\u001b[0m\u001b[1;32m   3008\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAGL0_saDjaN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}