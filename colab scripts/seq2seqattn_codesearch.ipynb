{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seqattn_codesearch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6aUn5xTaslU",
        "outputId": "01487eb4-7f9f-4550-ffb0-0914e6952db8"
      },
      "source": [
        "!wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
        "!unzip python.zip\n",
        "!gzip -d python/final/jsonl/test/python_test_0.jsonl.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-14 07:27:43--  https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.90.54\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.90.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 940909997 (897M) [application/zip]\n",
            "Saving to: ‘python.zip’\n",
            "\n",
            "python.zip          100%[===================>] 897.32M  35.4MB/s    in 26s     \n",
            "\n",
            "2020-12-14 07:28:10 (34.2 MB/s) - ‘python.zip’ saved [940909997/940909997]\n",
            "\n",
            "Archive:  python.zip\n",
            "   creating: python/\n",
            "   creating: python/final/\n",
            "   creating: python/final/jsonl/\n",
            "   creating: python/final/jsonl/train/\n",
            "  inflating: python/final/jsonl/train/python_train_9.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_12.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_10.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_0.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_6.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_2.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_4.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_8.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_11.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_5.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_13.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_3.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_1.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_7.jsonl.gz  \n",
            "   creating: python/final/jsonl/test/\n",
            "  inflating: python/final/jsonl/test/python_test_0.jsonl.gz  \n",
            "   creating: python/final/jsonl/valid/\n",
            "  inflating: python/final/jsonl/valid/python_valid_0.jsonl.gz  \n",
            "  inflating: python_dedupe_definitions_v2.pkl  \n",
            "  inflating: python_licenses.pkl     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIZduzbyea-0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "import re           \n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from keras import backend as K \n",
        "\n",
        "import copy\n",
        "import re\n",
        "import tarfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dRQokGpOdSYc",
        "outputId": "7e29d1ba-eaf3-42c3-9ee4-6420f9d56691"
      },
      "source": [
        "def get_python_data(remove_id=True, sample_size=50000, start_token='\\t', end_token='\\n'):\n",
        "  python_files = sorted(Path('python/').glob('**/*.gz'))\n",
        "  python_columns_list = ['repo', 'path', 'url', 'code', \n",
        "                  'code_tokens', 'docstring', 'docstring_tokens', \n",
        "                  'language', 'partition']\n",
        "\n",
        "  # Convert downloaded json files into a dataframe\n",
        "  python_data = pd.concat([pd.read_json(file,\n",
        "                          orient='records',\n",
        "                          compression='gzip',\n",
        "                          lines=True)[python_columns_list] for file in python_files],\n",
        "                          sort=False)\n",
        "  python_data['code'] = python_data['code'].str.replace(r'\\\"\"\".*?\"\"\"', '')\n",
        "  python_data['docstring'] = python_data['docstring'].str.replace(r'\\n', '')\n",
        "  python_data['docstring'] = python_data['docstring'].str.replace(r'\\t', '')\n",
        "  python_data = python_data[python_data['code'].str.len() < 750]\n",
        "  return python_data['code'].tolist()[:sample_size], python_data['docstring'].tolist()[:sample_size]\n",
        "\n",
        "input_data, target_data = get_python_data(start_token='', end_token='')\n",
        "\n",
        "df = pd.DataFrame({'Function': [], 'Comments': []})\n",
        "df['Function'] = input_data\n",
        "df['Comments'] = target_data\n",
        "\n",
        "df['Comments'] = 'sostok ' + df['Comments'] + ' eostok'\n",
        "\n",
        "max_len_text = max([len(txt.split()) for txt in input_data])\n",
        "max_len_summary = max([len(txt.split()) for txt in target_data])\n",
        "\n",
        "train_data,x_validation,train_labels,y_validation=train_test_split(df['Function'], df['Comments'],test_size=0.1,random_state=0,shuffle=True)\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(train_data))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "train_data    =   x_tokenizer.texts_to_sequences(train_data) \n",
        "x_validation   =   x_tokenizer.texts_to_sequences(x_validation)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "train_data    =   pad_sequences(train_data,  maxlen=max_len_text, padding='post') \n",
        "x_validation   =   pad_sequences(x_validation, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1\n",
        "\n",
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(train_labels))\n",
        "\n",
        "#convert summary sequences into integer sequences\n",
        "train_labels    =   y_tokenizer.texts_to_sequences(train_labels) \n",
        "y_validation   =   y_tokenizer.texts_to_sequences(y_validation) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "train_labels    =   pad_sequences(train_labels, maxlen=max_len_summary, padding='post')\n",
        "y_validation   =   pad_sequences(y_validation, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]\n",
        "\n",
        "K.clear_session() \n",
        "latent_dim = 512\n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attention_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attention_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "history=model.fit([train_data,train_labels[:,:-1]], train_labels.reshape(train_labels.shape[0],train_labels.shape[1], 1)[:,1:], epochs=50, steps_per_epoch=100, callbacks=[es],batch_size=64, validation_data=([x_validation,y_validationidation[:,:-1]], y_validation.reshape(y_validation.shape[0],y_validation.shape[1], 1)[:,1:]))\n",
        "\n",
        "reverse_target_word_index=y_tokenizer.index_word \n",
        "reverse_source_word_index=x_tokenizer.index_word \n",
        "target_word_index=y_tokenizer.word_index\n",
        "\n",
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attention_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    #print('input_seq: {}, e_out: {} '.format(input_seq,e_out))\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, 2:]) + 2\n",
        "        if sampled_token_index == 0:\n",
        "          print(\"keyerror\")\n",
        "          continue\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        #print(\"sampled_token:\",sampled_token)\n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        # stop_condition = True\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "def sequence_to_comment(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def sequence_to_code(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "\n",
        "results = pd.DataFrame({'Function':[], 'Original Comment':[], 'Predicted comment':[]})\n",
        "\n",
        "function, o_comment, p_comment = [], [], []\n",
        "for i in range(len(x_validation)):\n",
        "  function.append(sequence_to_code(x_validation[i]))\n",
        "  o_comment.append(sequence_to_comment(y_validation[i]))\n",
        "  p_comment.append(decode_sequence(x_validationidation[i].reshape(1,max_len_text)))\n",
        "\n",
        "results['Function'] = function\n",
        "results['Original Comment'] = o_comment\n",
        "results['Predicted comment'] = p_comment\n",
        "\n",
        "results.to_csv(\"results_seq2seq_attention_codesearch.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 142)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 142, 512)     33247744    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 142, 512), ( 2099200     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 142, 512), ( 2099200     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 512)    15270400    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 142, 512), ( 2099200     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 512),  2099200     embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 512),  524800      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1024)   0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 29825)  30570625    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 88,010,369\n",
            "Trainable params: 88,010,369\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "100/100 [==============================] - 66s 664ms/step - loss: 1.6736 - val_loss: 1.2704\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 65s 650ms/step - loss: 1.3063 - val_loss: 1.2039\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 65s 648ms/step - loss: 1.2370 - val_loss: 1.1476\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 65s 649ms/step - loss: 1.1735 - val_loss: 1.1074\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 64s 645ms/step - loss: 1.1697 - val_loss: 1.0808\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 64s 644ms/step - loss: 1.1235 - val_loss: 1.0557\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 65s 646ms/step - loss: 1.0782 - val_loss: 1.0425\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 64s 643ms/step - loss: 1.0589 - val_loss: 1.0056\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 64s 644ms/step - loss: 1.0405 - val_loss: 0.9827\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 65s 646ms/step - loss: 1.0048 - val_loss: 0.9500\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 64s 645ms/step - loss: 0.9688 - val_loss: 0.8753\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 65s 645ms/step - loss: 0.8612 - val_loss: 0.7396\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 64s 644ms/step - loss: 0.7402 - val_loss: 0.6304\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 64s 641ms/step - loss: 0.6281 - val_loss: 0.5498\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 64s 641ms/step - loss: 0.5431 - val_loss: 0.5000\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 64s 641ms/step - loss: 0.5055 - val_loss: 0.4626\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 64s 642ms/step - loss: 0.4799 - val_loss: 0.4330\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 64s 640ms/step - loss: 0.4525 - val_loss: 0.4087\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 64s 644ms/step - loss: 0.4241 - val_loss: 0.3987\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 64s 644ms/step - loss: 0.4148 - val_loss: 0.4179\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aXgZXFHeNOO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}